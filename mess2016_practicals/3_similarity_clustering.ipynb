{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-image:url(images/meschede-seismic-waves.png); padding: 10px 30px 20px 30px; background-size:cover; background-opacity:50%; border-radius:5px; background-position: 0px -200px\">\n",
    "<p style=\"float:right; margin-top:20px; padding: 20px 60px 0px 10px; background:rgba(255,255,255,0.75); border-radius:10px;\">\n",
    "<img width=\"400px\" src=images/obspy_logo_full_524x179px.png?raw=true>\n",
    "</p>\n",
    "\n",
    "<h1 style=\"color:#BBB; padding-bottom: 80px\">MESS 2016 - Practicals</h1>\n",
    "\n",
    "<h2 style=\"color:#FFF; padding-bottom: 30px\">Similarity Analysis /<br/>Hierarchical Clustering</h2>\n",
    "\n",
    "</div>\n",
    "\n",
    "### Please execute first cell to have plots show up inline (and scrollable/zoomable)\n",
    "### If you are unclear about how to use some ObsPy function: use search box at http://docs.obspy.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend(\"nbagg\")\n",
    "plt.style.use(\"bmh\")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message='The resource identifier.*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * read event data (file `clustering45_events.quakeml`)\n",
    " * read waveform data (file `clustering45_waveforms.mseed`)\n",
    " * print basic info of stream and catalog object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: read data, print info\n",
    "\n",
    "cat = \n",
    "st = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * iterate over catalog and assemble a list of picks for station \"UH1\", phase \"P\" (event data is set up such that each event holds exactly one P pick with these criteria)\n",
    " * note: if your computer is slow you can shorten the list to only 20 or 10 picks later on..\n",
    " * (Gold card members: Make the assembling of the list failsafe, i.e. account for events missing a \"P\" pick or having multiple \"P\" picks for this station, etc...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: assemble list of picks\n",
    "STATION = \"UH1\"\n",
    "PHASE = \"P\"\n",
    "\n",
    "picks = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * use function `get_matching_trace()` defined in the box below (execute box!) and fetch the corresponding traces for the first two picks in your list (if you had problems assembling the list of picks, use function `get_pick_list()` from below!)\n",
    " * use function `xcorr_pick_correction()` from `obspy.signal.cross_correlation` to calculate the correction time and maximum correlation coefficient for the second pick relative to the first pick (try with/without filtering options, use option `plot=True` to visualize the cross correlation) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_matching_trace(stream, pick):\n",
    "    \"\"\"\n",
    "    Extracts the appropriate Trace given a stream and a pick.\n",
    "    \n",
    "    stream: obspy Stream object\n",
    "    pick: obspy Pick object\n",
    "    \"\"\"\n",
    "    channel = pick.waveform_id.channel_code\n",
    "    station = pick.waveform_id.station_code\n",
    "    for tr in stream.select(station=station, channel=channel):\n",
    "        if tr.stats.starttime < pick.time < tr.stats.endtime:\n",
    "            return tr\n",
    "    else:\n",
    "        raise Exception(\"No matching trace found.\")\n",
    "\n",
    "# if you had problems getting the list of picks,\n",
    "# use this function which returns the list of picks..\n",
    "def get_pick_list():\n",
    "    \"\"\"\n",
    "    Returns a list of picks used in exercises below.\n",
    "    \"\"\"\n",
    "    from obspy import read_events\n",
    "    return [pick for event in read_events(\"data/clustering45_events.quakeml\")\n",
    "            for pick in event.picks\n",
    "            if pick.waveform_id.station_code == \"UH1\"\n",
    "            and pick.phase_hint == \"P\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO: cross-correlation pick alignment for two picks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * in the box below, we do the cross-correlation pick alignment for each pair of events and save the maximum correlation coefficient of the \"P\" pick on station \"UH1\" as the similarity\n",
    " * we plot a histogram of all correlation coefficients and the similarity matrix\n",
    " * you can play around wiht differnet settings in the pick alignment and see how it affects the similarity matrix\n",
    " * (Gold card members: Do similarity analysis using multiple stations, use average of stations as similarity; optionally include alos \"S\" picks in calculation (beware: picks might be set on different horizontal components!))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "from obspy.signal.cross_correlation import xcorr_pick_correction\n",
    "\n",
    "# if calculation takes too long on slow computers:\n",
    "# restrict length of pick list or use lower `cc_maxlag`\n",
    "similarity = np.eye(len(picks))\n",
    "for i, pick1 in enumerate(picks):\n",
    "    # here we select the correct trace for pick1\n",
    "    tr1 = get_matching_trace(st, pick1)\n",
    "    for j, pick2 in enumerate(picks):\n",
    "        if j <= i:\n",
    "            continue\n",
    "        tr2 = get_matching_trace(st, pick2)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            _, coeff = xcorr_pick_correction(\n",
    "                pick1.time, tr1, pick2.time, tr2,\n",
    "                t_before=0.05, t_after=0.2, cc_maxlag=0.10,\n",
    "                filter=\"bandpass\", filter_options={'freqmin': 1, 'freqmax': 20},\n",
    "                plot=False)\n",
    "        similarity[i, j] = coeff\n",
    "        similarity[j, i] = coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot histogram\n",
    "def plot_histogram(similarity):\n",
    "    plt.figure()\n",
    "    upper_triangle = similarity[np.triu_indices(similarity.shape[0], k=1)]\n",
    "    plt.hist(upper_triangle.flatten(), bins=np.linspace(0, 1, 21))\n",
    "    plt.ylabel(\"count\")\n",
    "    plt.xlabel(\"similarity\")\n",
    "    plt.show()\n",
    "\n",
    "plot_histogram(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * visualize similarity matrix using `matplotlib`'s `imshow()` function (avoid interpolation by setting `interpolation=\"nearest\"`)\n",
    " * (Gold card members: use a custom colormap, e.g. \"viridis\" from `obspy.imaging.cm`)\n",
    " * (Gold card members: plot the picks over time, to get an idea of the relative timing within groups of similar events)\n",
    " * optionally, save the similarity matrix to a numpy binary file using numpy's `save()` function\n",
    " * can you make out event clusters already in the matrix plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: visualize similarity matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Here we calculate the linkage of the similarity matrix (i.e. we do the agglomerative clustering) and plot the dendrogram of the resulting clusters (given a certain cut-off criterion in the clustering)\n",
    " * try different linkage methods (one of \"single\", \"complete\", \"average\", \"weighted\"; check documentation of `linkage` function to see what they do) and cut-off threshold values and see how it affects the clustering results\n",
    " * (Gold card members: plot corresponding seismograms in a subplot to the right, in line with dendrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "linkage_method = \"complete\"\n",
    "dissimilarity_threshold = 0.1\n",
    "\n",
    "\n",
    "distance = squareform(1 - similarity)\n",
    "linkage_matrix= linkage(distance, method=linkage_method)\n",
    "\n",
    "dendrogram(linkage_matrix, color_threshold=dissimilarity_threshold, orientation=\"right\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.axvline(dissimilarity_threshold, color=\"k\", ls=\"--\")\n",
    "plt.xlabel(\"dissimilarity\")\n",
    "plt.ylabel(\"event ID\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
