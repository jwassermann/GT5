{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-image:url(images/meschede-seismic-waves.png); padding: 10px 30px 20px 30px; background-size:cover; background-opacity:50%; border-radius:5px; background-position: 0px -200px\">\n",
    "<p style=\"float:right; margin-top:20px; padding: 20px 60px 0px 10px; background:rgba(255,255,255,0.75); border-radius:10px;\">\n",
    "<img width=\"400px\" src=images/obspy_logo_full_524x179px.png?raw=true>\n",
    "</p>\n",
    "\n",
    "<h1 style=\"color:#BBB; padding-bottom: 80px\">MESS 2016 - Practicals</h1>\n",
    "\n",
    "<h2 style=\"color:#FFF; padding-bottom: 30px\">Master Event Relocation</h2>\n",
    "\n",
    "</div>\n",
    "\n",
    "### Please execute first cell to have plots show up inline (and scrollable/zoomable)\n",
    "### If you are unclear about how to use some ObsPy function: use search box at http://docs.obspy.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend(\"nbagg\")\n",
    "plt.style.use(\"bmh\")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message='The resource identifier.*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * load clustering catalog using obspy (file `data/clustering45_events.quakeml`, `read_events` function)\n",
    " * load station inventory (file `data/station_UH_all.stationxml`, `read_inventory` function)\n",
    " * load clustering similarity matrix using numpy.load (file `data/clustering45_similarity.npy`, numpy `load` function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "\n",
    "# we use these variable names below, so please adhere to these names\n",
    "cat = \n",
    "similarity = \n",
    "inv = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * execute cell below to get a display of the similarity and dendrogram again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot read in similarity and visualize dendrogram\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from scipy.spatial.distance import squareform\n",
    "import matplotlib.pyplot as plt\n",
    "from obspy.imaging.cm import viridis\n",
    "\n",
    "\n",
    "def plot_similarity(similarity, dissimilarity_threshold=0.1, method=\"complete\"):\n",
    "    \"\"\"\n",
    "    Plot similarity matrix\n",
    "    \n",
    "    similarity: numpy ndarray\n",
    "    dissimilarity_threshold: float, cut-off value for clustering\n",
    "    method: str, agglomerative clustering criterion\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(10, 15))\n",
    "    ax1 = fig.add_subplot(2, 1, 1)\n",
    "    ax2 = fig.add_subplot(2, 1, 2)\n",
    "\n",
    "    im = ax1.imshow(similarity, interpolation=\"nearest\", cmap=viridis)\n",
    "    ax1.set_xlabel(\"event index\")\n",
    "    ax1.set_ylabel(\"event index\")\n",
    "    ax1.grid(False)\n",
    "    cb = plt.colorbar(mappable=im, ax=ax1)\n",
    "    cb.ax.set_ylabel(\"similarity\")\n",
    "\n",
    "    distance = 1 - similarity\n",
    "    link = linkage(squareform(distance), method=method)\n",
    "\n",
    "    dendrogram(link, color_threshold=dissimilarity_threshold, orientation=\"right\", ax=ax2)\n",
    "    \n",
    "    clusters = fcluster(link, dissimilarity_threshold, criterion=\"distance\")\n",
    "    for i in range(1, clusters.max() + 1):\n",
    "        indices = np.where(clusters == i)[0].tolist()\n",
    "        print(\"cluster no. {}: {}\".format(i, indices)) \n",
    "    \n",
    "    ax2.axvline(dissimilarity_threshold, color=\"k\", ls=\"--\")\n",
    "    ax2.set_xlabel(\"dissimilarity\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "plot_similarity(similarity, dissimilarity_threshold=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Master event relocation](images/master-event.png)\n",
    "\n",
    " * take the first station from the inventory and the first event in the catalog and set up a unit vector pointing from source to station (strong simplification for the sake of simplicity, assuming a simple straight line for the ray)\n",
    "   * use e.g. `gps2dist_azimuth` function from `obspy.geodetics` and `math` module (`sin`, `cos`, `pi`, `radians`, ...)\n",
    "   * note: convert from azimuth to mathematical angle..\n",
    " * you can use the plotting function in the box below to check your calculation\n",
    " * (Gold card members: use take-off angle and azimuth information for a phase stored as an arrival in origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "\n",
    "\n",
    "# we use these names as the three components of the unit vector,\n",
    "# please stick to these variable names so the box below can plot your vector\n",
    "dx =\n",
    "dy =\n",
    "dz ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "def plot_unit_vector(event, station, dx, dy, dz, fig=None, show=True):\n",
    "    \"\"\"\n",
    "    Plot event, station and unit vector from source to station\n",
    "    \n",
    "    event: obspy Event object\n",
    "    station: obspy Station object\n",
    "    dx, dy, dz: floats\n",
    "    \"\"\"\n",
    "    origin = event.origins[0]\n",
    "    if not fig:\n",
    "        fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    # plot markers for event + station\n",
    "    ax.scatter(origin.longitude, origin.latitude, s=300, marker=\"*\", color=\"g\")\n",
    "    ax.scatter(station.longitude, station.latitude, s=200, marker=\"v\")\n",
    "    # add text labels for event + station\n",
    "    ax.text(origin.longitude, origin.latitude, \"  \" + str(event.resource_id).split(\"/\")[-1])\n",
    "    ax.text(station.longitude, station.latitude, \"  \" + station.code)\n",
    "    # plot unit vector (scale it arbitrarily to the plot size)\n",
    "    scale_factor = 0.03\n",
    "    # need to take latitude into account: no equal data scale in meters!\n",
    "    latitude_correction = cos(radians(origin.latitude))\n",
    "    dx *= scale_factor / latitude_correction\n",
    "    dy *= scale_factor\n",
    "    ax.plot([origin.longitude, origin.longitude + dx],\n",
    "            [origin.latitude, origin.latitude + dy],\n",
    "            \"r-\", zorder=-1)\n",
    "    ax.set_xlabel(\"Longitude\")\n",
    "    ax.set_ylabel(\"Latitude\")\n",
    "    ax.xaxis.set_major_formatter(FormatStrFormatter(\"%s\"))\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter(\"%s\"))\n",
    "    ax.set_aspect(latitude_correction, adjustable=\"datalim\")\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "plot_unit_vector(event, station, dx, dy, dz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * below are two functions that do the unit vector calculation for all stations in the inventory\n",
    " * execute the box, so the functions are available for the master-event relocation below\n",
    " * (Gold card member exercise: replace unit vector calculation with take-off angle and azimuth from arrival information stored in origin, coming from NonLinLoc location run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sin, cos, radians\n",
    "from obspy.geodetics import gps2dist_azimuth\n",
    "\n",
    "\n",
    "def coordinates_to_unitvector(event, station_code, inventory, plot=False, fig=None, show=True):\n",
    "    \"\"\"\n",
    "    Compute (x, y, z) unit vector pointing from source to receiver along the\n",
    "    straight line connecting origin and receiver.\n",
    "    \n",
    "    event: obspy Event object\n",
    "    station_code: station name as string (e.g. \"UH1\")\n",
    "    inventory: obspy Inventory object\n",
    "    plot: boolean, wheteher to show a plot\n",
    "    \n",
    "    returns: unit vector as three floats (x, y, z)\n",
    "    \"\"\"\n",
    "    origin = event.origins[0]\n",
    "    station_coordinates = inventory.get_coordinates(\n",
    "        \"BW.{}..EHZ\".format(station_code), datetime=origin.time)\n",
    "    distance, azimuth, backazimuth = gps2dist_azimuth(\n",
    "        origin.latitude, origin.longitude,\n",
    "        station_coordinates['latitude'], station_coordinates['longitude']) \n",
    "    dz = origin.depth + station_coordinates['elevation']\n",
    "    angle = radians(90 - azimuth)\n",
    "    dx = distance * cos(angle)\n",
    "    dy = distance * sin(angle)\n",
    "    norm = np.linalg.norm((dx, dy, dz))\n",
    "    dx /=  norm\n",
    "    dy /=  norm\n",
    "    dz /=  norm\n",
    "\n",
    "    if plot:\n",
    "        sta=None\n",
    "        for net in inv:\n",
    "            for sta in net:\n",
    "                if sta.code == station_code:\n",
    "                    break\n",
    "        plot_unit_vector(event, sta, dx, dy, dz, fig=fig, show=show)\n",
    "\n",
    "    return (dx, dy, dz)\n",
    "\n",
    "def all_coordinates_to_unitvectors(event, inventory, plot=True):\n",
    "    unit_vectors = {}\n",
    "    station_codes = set([sta.code for net in inv for sta in net])\n",
    "    if plot:\n",
    "        fig = plt.figure(figsize=(11, 4))\n",
    "    else:\n",
    "        fig=None\n",
    "    for sta in station_codes:\n",
    "        unit_vectors[sta] = coordinates_to_unitvector(\n",
    "            cat[0], sta, inv, plot=plot, fig=fig, show=False)\n",
    "    if plot:\n",
    "        plt.show()\n",
    "    return unit_vectors\n",
    "\n",
    "event = cat[0]\n",
    "all_coordinates_to_unitvectors(event, inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * below are two helper functions..\n",
    "   * ..to get the matching pick from a second event\n",
    "   * ..to calculate a differential travel time for a given pick from a master event and a slave event\n",
    " * execute the box, so the functions are available for the master-event relocation below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy import read\n",
    "from obspy.signal.cross_correlation import xcorr_pick_correction\n",
    "\n",
    "ST = read(\"data/clustering45_waveforms.mseed\")\n",
    "\n",
    "\n",
    "def get_corresponding_pick(pick, event):\n",
    "    \"\"\"\n",
    "    Extract the corresponding pick from an event (slave event),\n",
    "    given a pick from a different event (master event).\n",
    "    \n",
    "    pick: obspy Pick object\n",
    "    event: obspy Event object\n",
    "    \n",
    "    returns: Pick object or None if no corresponding pick was found\n",
    "    \"\"\"\n",
    "    pick2 = None\n",
    "    for pick2 in event.picks:\n",
    "        if (pick2.waveform_id.station_code == pick.waveform_id.station_code\n",
    "                and pick2.phase_hint == pick.phase_hint):\n",
    "            return pick2\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "def get_differential_traveltime(pick_master, event_slave, st=None, refine=False,\n",
    "                                plot=False, xcorr_threshold=0.7):\n",
    "    \"\"\"\n",
    "    Get differential travel time given a pick from a master event and a slave event.\n",
    "    Optionally refine differential travel time with cross correlation.\n",
    "    \n",
    "    pick_master: obspy Pick object\n",
    "    event_slave: obspy Event object\n",
    "    st: obspy Stream object containing waveforms for cross correlation\n",
    "    refine: boolean, whether to cross-correlation-align picks\n",
    "    \"\"\"\n",
    "    # get matching \n",
    "    pick_slave = get_corresponding_pick(pick_master, event_slave)\n",
    "    if not pick_slave or not pick_slave.time:\n",
    "        return None\n",
    "    dt = pick_slave.time - pick_master.time\n",
    "    # refine differential travel time by cross-correlation-aligning of picks\n",
    "    if refine:\n",
    "        tr_master = [tr_ for tr_ in ST\n",
    "                     if tr_.stats.starttime < pick_master.time < tr_.stats.endtime\n",
    "                     and tr_.id == pick_master.waveform_id.get_seed_string()][0].copy()\n",
    "        tr_slave = [tr_ for tr_ in ST\n",
    "                    if tr_.stats.starttime < pick_slave.time < tr_.stats.endtime\n",
    "                    and tr_.id == pick_slave.waveform_id.get_seed_string()][0].copy()\n",
    "        # cross-correlation pick alignment\n",
    "        t_correction, coeff = xcorr_pick_correction(\n",
    "            pick_master.time, tr_master, pick_slave.time, tr_slave,\n",
    "            t_before=0.05, t_after=0.2, cc_maxlag=0.1, filter=\"bandpass\",\n",
    "            filter_options={\"freqmin\": 1, \"freqmax\": 20}, plot=plot)\n",
    "        # discard picks that have low cross-correlation\n",
    "        if coeff < xcorr_threshold:\n",
    "            print(\"Pick discarded (coeff: {:.2f})\".format(coeff))\n",
    "            return None\n",
    "        # adjust slave pick time\n",
    "        dt += t_correction\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * below are two functions to execute the master-event relocation, execute the code cells to be able to use them below\n",
    "\n",
    "![Master event relocation](images/master-event.png)\n",
    "![Master event relocation](images/pinv.png)\n",
    "\n",
    " * (Gold card member exercise: Add weighting (e.g. by correlation coefficient of pick) to the inversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from obspy import Catalog, read\n",
    "\n",
    "def relocate_event(master, slave, inventory, velocities, refine):\n",
    "    \"\"\"\n",
    "    Relocate a single slave event relative to master event.\n",
    "    \n",
    "    master: obspy Event object\n",
    "    slave: obspy Event object\n",
    "    inventory: obspy Inventory object\n",
    "    velocities: dictionary with keys \"P\" and \"S\" giving wave velocities in source region in m/s.\n",
    "    refine: boolean, whether to cross-correlation-align picks\n",
    "    \n",
    "    returns: Hypocenter of slave location in relative coordinates to master (dt, dx, dy, dz)\n",
    "    \"\"\"\n",
    "    unit_vectors = all_coordinates_to_unitvectors(master, inv, plot=False)\n",
    "    data_vector = []\n",
    "    forward_operator_matrix = []\n",
    "    # assemble data vector and forward operator matrix,\n",
    "    # iterating over all usable picks\n",
    "    for pick in master.picks:\n",
    "        if pick.waveform_id.station_code not in unit_vectors:\n",
    "            continue\n",
    "        # get differential travel time\n",
    "        dt = get_differential_traveltime(pick, slave, refine=refine)\n",
    "        if dt is None:\n",
    "            continue\n",
    "        # extract the correct unit vector for the pick\n",
    "        x, y, z = unit_vectors[pick.waveform_id.station_code]\n",
    "        vel = velocities[pick.phase_hint]\n",
    "        # forward operator setup, see image above\n",
    "        operator_line = (1.0, -x/vel, -y/vel, -z/vel)\n",
    "        data_vector.append(dt)\n",
    "        forward_operator_matrix.append(operator_line)\n",
    "    # convert lists to numpy arrays\n",
    "    data_vector = np.array(data_vector)\n",
    "    forward_operator_matrix = np.array(forward_operator_matrix)\n",
    "    # compute moore-penrose pseudo inverse\n",
    "    inverse_operator_matrix = np.linalg.pinv(forward_operator_matrix)\n",
    "    # apply inverted operator to data vector\n",
    "    relative_location = np.dot(inverse_operator_matrix, data_vector)\n",
    "    dt_origin, dx, dy, dz = relative_location\n",
    "    return dt_origin, dx, dy, dz\n",
    "    \n",
    "\n",
    "def relocate_events(catalog, master_event_id, inventory, velocities, refine):\n",
    "    \"\"\"\n",
    "    Relocate a set of events, specifying the index which event should be used as master event.\n",
    "    Shows a plot of the relocation results with master event at coordinate origin.\n",
    "    \n",
    "    catalog: obspy Catalog object\n",
    "    master_event_id: integer, master event number (as shown in similarity plot above)\n",
    "    inventory: obspy Inventory object\n",
    "    velocities: dictionary with keys \"P\" and \"S\" giving wave velocities in source region in m/s.\n",
    "    refine: boolean, whether to cross-correlation-align picks\n",
    "    \n",
    "    returns: Hypocenter of slave location in relative coordinates to master (dt, dx, dy, dz)\n",
    "    \"\"\"\n",
    "    for event in catalog:\n",
    "        if int(str(event.resource_id).split(\"/\")[-1]) == master_event_id:\n",
    "            master = event\n",
    "            break\n",
    "    else:\n",
    "        raise Exception(\"Could not find master event with ID {}\".format(master_event_id))\n",
    "    slaves = Catalog()\n",
    "    for event in catalog:\n",
    "        if event != master:\n",
    "            slaves.append(event)\n",
    "\n",
    "    master_event_number = str(master.resource_id).split(\"/\")[-1]\n",
    "    plt.figure()\n",
    "    plt.title(\"Master Event: {}\".format(master_event_number))\n",
    "    plt.scatter(0, 0, s=200, marker=\"*\", color=\"r\")\n",
    "    plt.text(0, 0, \"  \" + master_event_number)\n",
    "    for slave in slaves:\n",
    "        dt_origin, dx, dy, dz = relocate_event(\n",
    "            master, slave, inventory, velocities, refine=refine)\n",
    "        # print dt_origin, dx, dy, dz\n",
    "        plt.scatter(dx, dy, s=200, marker=\"*\", color=\"g\")\n",
    "        plt.text(dx, dy, \"  \" + str(slave.resource_id).split(\"/\")[-1])\n",
    "    plt.gca().set_aspect(\"equal\", adjustable=\"datalim\")\n",
    "    plt.xlabel(\"x [m]\")\n",
    "    plt.ylabel(\"y [m]\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * set up a new catalog with one of the clusters shown in the dendrogram above (use the event indices shown in the dendrogram)\n",
    " * set up a dictionary with keys \"P\" and \"S\" (for velocities), use P-wave velocity 5000 (m/s) and S-wave velocity 2700 (m/s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "from obspy import Catalog, read\n",
    "\n",
    "new_cat = \n",
    "\n",
    "velocities ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * visualize the master-event relocations using 2-3 events as a master in turn,\n",
    "   without cross-correlation refinement of picks (`refine=False`); use `relocate_events()` function defined in the above box\n",
    " * what differences and/or common aspects do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "relocate_events(...)\n",
    "relocate_events(...)\n",
    "relocate_events(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * again: visualize the master-event relocations using 2-3 events as a master in turn but now *with* cross-correlation pick refinement (option `refine=True`)\n",
    " * what are the differences to before (event separation distances, general looks of the cluster, etc.)?\n",
    " * compare relative location of events to their positioning in the dendrogram above\n",
    " * (Gold card members: add the relocation results to the existing event object as new origin objects (use `obspy.signal.util.util_lon_lat` to convert relative to geographical coordinates), set them as preferred origin, save to QuakeML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "import warnings\n",
    "# cross correlation pick alignment shows many warnings on bad correlations,\n",
    "# here we catch most of them to have less verbose output\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"once\")\n",
    "    relocate_events(...)\n",
    "    relocate_events(...)\n",
    "    relocate_events(...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
